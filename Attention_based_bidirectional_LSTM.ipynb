{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_based bidirectional LSTM.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyZyLNT0lPGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "91e62bef-7281-46c6-c265-6c16a06ff4f0"
      },
      "source": [
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import model_from_json\n",
        "\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Concatenate\n",
        "import keras.layers as lyr\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Bidirectional\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueaQZju8lTp4",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfbO0-NznPS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_CSV = '/questions.csv'\n",
        "#TRAIN_CSV = 'sample.csv'\n",
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAUvnc2-nSIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64a833a6-8b00-46c3-f3ae-014c324e17bf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "stops = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdufe8U1r1r1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "531e23c0-3a2d-4d32-b136-aecac42be516"
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-24 07:17:55--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.81.22\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.81.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.2MB/s    in 1m 50s  \n",
            "\n",
            "2020-07-24 07:19:46 (14.3 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htGnILw0nWXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stringToWordList(text):\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\(\", \" ( \", text)\n",
        "    text = re.sub(r\"\\)\", \" ) \", text)\n",
        "    text = re.sub(r\"\\?\", \" ? \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = text.split()\n",
        "    return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58b3Whn2pE1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "757624cf-d0fb-4eab-f9e5-0814e2ba1ca6"
      },
      "source": [
        "questions_cols = ['question1', 'question2']\n",
        "vocab = dict()\n",
        "maxSeqLength = 0\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    for question in questions_cols:\n",
        "        q2num = []\n",
        "        for word in stringToWordList(row[question]):\n",
        "            if word in stops and word not in word2vec.vocab:\n",
        "                continue\n",
        "            if word not in vocab:\n",
        "                vocab[word] = len(vocab)+1\n",
        "            q2num.append(vocab[word])\n",
        "        train_df.at[index,question] = q2num\n",
        "        if len(q2num) > maxSeqLength:\n",
        "            maxSeqLength = len(q2num)\n",
        "\n",
        "embeddingDim = 300\n",
        "embeddings = 1 * np.random.randn(len(vocab) + 1, embeddingDim)\n",
        "embeddings[0] = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OSUO53FpOgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the embedding matrix\n",
        "for word, index in vocab.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embeddings[index] = word2vec.word_vec(word)\n",
        "\n",
        "del word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT-2QSZhvSRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 20000\n",
        "validation_size = 40000\n",
        "training_size = len(train_df) - validation_size\n",
        "\n",
        "X = train_df[questions_cols]\n",
        "Y = train_df['is_duplicate']\n",
        "\n",
        "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=test_size)\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train_val, Y_train_val, test_size=validation_size)\n",
        "\n",
        "# Split to dicts\n",
        "X_train = {'left': X_train.question1, 'right': X_train.question2}\n",
        "X_test = {'left': X_test.question1, 'right': X_test.question2}\n",
        "X_validation = {'left': X_validation.question1, 'right': X_validation.question2}\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "Y_train = Y_train.values\n",
        "Y_test = Y_test.values\n",
        "Y_validation = Y_validation.values\n",
        "\n",
        "# Zero padding\n",
        "for dataset, side in itertools.product([X_train, X_validation, X_test], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=maxSeqLength)\n",
        "\n",
        "# Make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FqOjyAFvWnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import dot, Dense , Flatten , Reshape , add , Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "n_hidden = 50\n",
        "gradient_clipping_norm = 1.25\n",
        "batch_size = 1024\n",
        "n_epoch = 2\n",
        "\n",
        "DROPOUT =  0.1\n",
        "\n",
        "question1 = Input(shape=(maxSeqLength,))\n",
        "question2 = Input(shape=(maxSeqLength,))\n",
        "\n",
        "q1 = Embedding(len(embeddings), \n",
        "                 embeddingDim,\n",
        "                 weights=[embeddings], \n",
        "                 input_length=maxSeqLength, \n",
        "                 trainable=False)(question1)\n",
        "q1 = Bidirectional(LSTM(n_hidden, return_sequences=True), merge_mode=\"sum\")(q1)\n",
        "\n",
        "q2 = Embedding(len(embeddings), \n",
        "                 embeddingDim, \n",
        "                 weights=[embeddings], \n",
        "                 input_length=maxSeqLength, \n",
        "                 trainable=False)(question2)\n",
        "q2 = Bidirectional(LSTM(n_hidden, return_sequences=True), merge_mode=\"sum\")(q2)\n",
        "\n",
        "attention = dot([q1,q2], [1,1])\n",
        "attention = Flatten()(attention)\n",
        "attention = Dense((maxSeqLength*n_hidden))(attention)\n",
        "attention = Reshape((maxSeqLength, n_hidden))(attention)\n",
        "\n",
        "merged = add([q1,attention])\n",
        "merged = Flatten()(merged)\n",
        "merged = Dense(200, activation='relu')(merged)\n",
        "merged = Dropout(DROPOUT)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "merged = Dense(200, activation='relu')(merged)\n",
        "merged = Dropout(DROPOUT)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "merged = Dense(200, activation='relu')(merged)\n",
        "merged = Dropout(DROPOUT)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "merged = Dense(200, activation='relu')(merged)\n",
        "merged = Dropout(DROPOUT)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wog0hLhveFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6529fe83-e5b5-4d81-aaa5-382367cdf68d"
      },
      "source": [
        "# Start training\n",
        "training_start_time = time()\n",
        "\n",
        "lstm_trained = model.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size,epochs=n_epoch,\n",
        "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
        "\n",
        "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 344351 samples, validate on 40000 samples\n",
            "Epoch 1/2\n",
            "344351/344351 [==============================] - 5264s 15ms/step - loss: 0.5288 - accuracy: 0.7306 - val_loss: 0.4691 - val_accuracy: 0.7664\n",
            "Epoch 2/2\n",
            "344351/344351 [==============================] - 4986s 14ms/step - loss: 0.4402 - accuracy: 0.7863 - val_loss: 0.4476 - val_accuracy: 0.7839\n",
            "Training time finished.\n",
            "2 epochs in 2:50:55.662115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU8nogB-vjEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0824e5a2-9b5a-41ef-c95a-57c0a042e4cf"
      },
      "source": [
        "scores = model.evaluate([X_test['left'], X_test['right']], Y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 78.62%\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aoub_GmX8Rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}