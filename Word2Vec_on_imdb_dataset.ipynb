{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGES LOADED\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import os\n",
    "import nltk.data\n",
    "import string\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "print (\"PACKAGES LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following class defined a Python generator which parses all files (recursively) in a given directory, \n",
    "#and yields the sentences there one at a time (thus saving loads of memory).\n",
    "class SentGen(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for path,dirs,files in os.walk(self.dirname):\n",
    "            for fname in files:\n",
    "                for line in get_sentences(path + '/' + fname):\n",
    "                    yield line.split()\n",
    "\n",
    "def get_sentences(fname):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    fp = open(fname, 'r', encoding=\"utf-8\")\n",
    "    data = fp.read()\n",
    "    fp.close()\n",
    "    trans_table = dict((ord(char), None) for char in string.punctuation)\n",
    "    sentences = nltk.sent_tokenize(data)\n",
    "    for sent in sentences:\n",
    "        yield sent.translate(trans_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty model\n",
    "model = gensim.models.Word2Vec(iter=1, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-08 12:13:03,420 : INFO : collecting all words and their counts\n",
      "2020-02-08 12:13:03,437 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-08 12:13:21,659 : INFO : PROGRESS: at sentence #200000, processed 4235964 words, keeping 117989 word types\n",
      "2020-02-08 12:13:39,825 : INFO : PROGRESS: at sentence #400000, processed 8470628 words, keeping 177074 word types\n",
      "2020-02-08 12:13:58,857 : INFO : PROGRESS: at sentence #600000, processed 12910549 words, keeping 229396 word types\n",
      "2020-02-08 12:16:08,387 : INFO : PROGRESS: at sentence #800000, processed 17357138 words, keeping 275456 word types\n",
      "2020-02-08 12:18:47,015 : INFO : PROGRESS: at sentence #1000000, processed 21567523 words, keeping 315310 word types\n",
      "2020-02-08 12:19:54,228 : INFO : collected 329953 word types from a corpus of 23197079 raw words and 1074524 sentences\n",
      "2020-02-08 12:19:54,230 : INFO : Loading a fresh vocabulary\n",
      "2020-02-08 12:19:54,609 : INFO : effective_min_count=5 retains 75839 unique words (22% of original 329953, drops 254114)\n",
      "2020-02-08 12:19:54,611 : INFO : effective_min_count=5 leaves 22838567 word corpus (98% of original 23197079, drops 358512)\n",
      "2020-02-08 12:19:55,056 : INFO : deleting the raw counts dictionary of 329953 items\n",
      "2020-02-08 12:19:55,066 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-08 12:19:55,069 : INFO : downsampling leaves estimated 17632093 word corpus (77.2% of prior 22838567)\n",
      "2020-02-08 12:19:55,438 : INFO : estimated required memory for 75839 words and 100 dimensions: 98590700 bytes\n",
      "2020-02-08 12:19:55,439 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(SentGen('aclImdb'), progress_per=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2020-02-08 12:22:19,099 : INFO : training model with 3 workers on 75839 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-08 12:22:21,155 : INFO : EPOCH 1 - PROGRESS: at 0.04% examples, 3822 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:22:29,441 : INFO : EPOCH 1 - PROGRESS: at 1.21% examples, 19995 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:22:37,506 : INFO : EPOCH 1 - PROGRESS: at 3.41% examples, 31519 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:22:45,665 : INFO : EPOCH 1 - PROGRESS: at 5.30% examples, 33898 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:22:53,683 : INFO : EPOCH 1 - PROGRESS: at 6.87% examples, 33720 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:01,830 : INFO : EPOCH 1 - PROGRESS: at 8.80% examples, 34967 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:10,133 : INFO : EPOCH 1 - PROGRESS: at 9.71% examples, 32259 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:18,421 : INFO : EPOCH 1 - PROGRESS: at 10.73% examples, 30705 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:26,691 : INFO : EPOCH 1 - PROGRESS: at 11.73% examples, 29530 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:34,731 : INFO : EPOCH 1 - PROGRESS: at 12.74% examples, 28697 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:42,765 : INFO : EPOCH 1 - PROGRESS: at 13.66% examples, 27923 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:51,049 : INFO : EPOCH 1 - PROGRESS: at 14.63% examples, 27294 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:23:59,124 : INFO : EPOCH 1 - PROGRESS: at 15.53% examples, 26679 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:24:07,438 : INFO : EPOCH 1 - PROGRESS: at 16.52% examples, 26304 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:24:15,637 : INFO : EPOCH 1 - PROGRESS: at 17.54% examples, 26008 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:24:23,725 : INFO : EPOCH 1 - PROGRESS: at 18.52% examples, 25720 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:24:32,332 : INFO : EPOCH 1 - PROGRESS: at 19.52% examples, 25419 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:24:40,390 : INFO : EPOCH 1 - PROGRESS: at 20.34% examples, 25037 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:24:48,561 : INFO : EPOCH 1 - PROGRESS: at 21.39% examples, 24934 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:24:56,605 : INFO : EPOCH 1 - PROGRESS: at 22.41% examples, 24762 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:25:04,836 : INFO : EPOCH 1 - PROGRESS: at 23.47% examples, 24719 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:25:13,163 : INFO : EPOCH 1 - PROGRESS: at 24.52% examples, 24622 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:25:21,310 : INFO : EPOCH 1 - PROGRESS: at 25.63% examples, 24564 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:25:29,576 : INFO : EPOCH 1 - PROGRESS: at 26.76% examples, 24498 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:25:37,871 : INFO : EPOCH 1 - PROGRESS: at 27.92% examples, 24472 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:25:45,924 : INFO : EPOCH 1 - PROGRESS: at 29.02% examples, 24403 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:25:54,106 : INFO : EPOCH 1 - PROGRESS: at 30.15% examples, 24360 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:02,173 : INFO : EPOCH 1 - PROGRESS: at 31.79% examples, 24743 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:10,242 : INFO : EPOCH 1 - PROGRESS: at 32.88% examples, 24704 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:18,488 : INFO : EPOCH 1 - PROGRESS: at 33.97% examples, 24616 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:26,862 : INFO : EPOCH 1 - PROGRESS: at 35.16% examples, 24582 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:34,868 : INFO : EPOCH 1 - PROGRESS: at 36.27% examples, 24556 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:42,926 : INFO : EPOCH 1 - PROGRESS: at 37.34% examples, 24499 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:51,143 : INFO : EPOCH 1 - PROGRESS: at 38.37% examples, 24455 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:26:59,159 : INFO : EPOCH 1 - PROGRESS: at 39.40% examples, 24430 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:27:07,167 : INFO : EPOCH 1 - PROGRESS: at 40.43% examples, 24409 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:27:15,307 : INFO : EPOCH 1 - PROGRESS: at 41.56% examples, 24405 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:27:23,642 : INFO : EPOCH 1 - PROGRESS: at 42.57% examples, 24335 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:27:31,841 : INFO : EPOCH 1 - PROGRESS: at 43.62% examples, 24325 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:27:40,058 : INFO : EPOCH 1 - PROGRESS: at 44.61% examples, 24267 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:27:48,214 : INFO : EPOCH 1 - PROGRESS: at 45.66% examples, 24239 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:27:56,244 : INFO : EPOCH 1 - PROGRESS: at 46.73% examples, 24245 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:28:04,614 : INFO : EPOCH 1 - PROGRESS: at 47.49% examples, 24052 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:28:12,815 : INFO : EPOCH 1 - PROGRESS: at 48.17% examples, 23837 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:28:21,166 : INFO : EPOCH 1 - PROGRESS: at 48.78% examples, 23600 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:28:29,397 : INFO : EPOCH 1 - PROGRESS: at 49.57% examples, 23463 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:28:37,556 : INFO : EPOCH 1 - PROGRESS: at 50.43% examples, 23358 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:28:45,713 : INFO : EPOCH 1 - PROGRESS: at 51.28% examples, 23258 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:28:54,024 : INFO : EPOCH 1 - PROGRESS: at 52.15% examples, 23171 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:29:02,321 : INFO : EPOCH 1 - PROGRESS: at 53.06% examples, 23088 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:29:10,646 : INFO : EPOCH 1 - PROGRESS: at 54.04% examples, 23044 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:29:18,886 : INFO : EPOCH 1 - PROGRESS: at 54.97% examples, 23007 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:29:27,115 : INFO : EPOCH 1 - PROGRESS: at 55.95% examples, 22973 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:29:35,343 : INFO : EPOCH 1 - PROGRESS: at 56.98% examples, 22975 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:29:43,575 : INFO : EPOCH 1 - PROGRESS: at 57.82% examples, 22891 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:29:51,907 : INFO : EPOCH 1 - PROGRESS: at 58.79% examples, 22871 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:00,034 : INFO : EPOCH 1 - PROGRESS: at 59.83% examples, 22879 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:08,167 : INFO : EPOCH 1 - PROGRESS: at 60.84% examples, 22870 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:16,528 : INFO : EPOCH 1 - PROGRESS: at 61.89% examples, 22868 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:24,759 : INFO : EPOCH 1 - PROGRESS: at 62.90% examples, 22856 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:32,880 : INFO : EPOCH 1 - PROGRESS: at 63.92% examples, 22850 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:40,908 : INFO : EPOCH 1 - PROGRESS: at 64.88% examples, 22832 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:49,096 : INFO : EPOCH 1 - PROGRESS: at 65.92% examples, 22837 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:30:57,211 : INFO : EPOCH 1 - PROGRESS: at 67.03% examples, 22860 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:31:05,289 : INFO : EPOCH 1 - PROGRESS: at 67.99% examples, 22840 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:31:13,387 : INFO : EPOCH 1 - PROGRESS: at 68.93% examples, 22818 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:31:21,608 : INFO : EPOCH 1 - PROGRESS: at 69.99% examples, 22822 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:31:29,876 : INFO : EPOCH 1 - PROGRESS: at 71.09% examples, 22851 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:31:37,966 : INFO : EPOCH 1 - PROGRESS: at 72.15% examples, 22857 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:31:46,185 : INFO : EPOCH 1 - PROGRESS: at 73.16% examples, 22846 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-08 12:31:54,192 : INFO : EPOCH 1 - PROGRESS: at 74.12% examples, 22829 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:32:02,410 : INFO : EPOCH 1 - PROGRESS: at 75.13% examples, 22807 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:32:10,585 : INFO : EPOCH 1 - PROGRESS: at 76.17% examples, 22800 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:32:18,599 : INFO : EPOCH 1 - PROGRESS: at 80.30% examples, 23675 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:32:26,622 : INFO : EPOCH 1 - PROGRESS: at 85.52% examples, 24841 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:32:34,669 : INFO : EPOCH 1 - PROGRESS: at 90.96% examples, 26036 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:32:42,676 : INFO : EPOCH 1 - PROGRESS: at 95.60% examples, 27003 words/s, in_qsize 0, out_qsize 0\n",
      "2020-02-08 12:32:49,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-08 12:32:49,190 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-08 12:32:49,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-08 12:32:49,210 : INFO : EPOCH - 1 : training on 23197079 raw words (17631244 effective words) took 630.0s, 27985 effective words/s\n",
      "2020-02-08 12:32:49,211 : INFO : training on a 23197079 raw words (17631244 effective words) took 630.1s, 27981 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17631244, 23197079)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(SentGen('aclImdb'), total_examples=model.corpus_count,epochs=model.iter, report_delay=8.0)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-08 12:43:04,729 : INFO : saving Word2Vec object under aclImdb.model, separately None\n",
      "2020-02-08 12:43:04,731 : INFO : not storing attribute vectors_norm\n",
      "2020-02-08 12:43:04,734 : INFO : not storing attribute cum_table\n",
      "2020-02-08 12:43:06,954 : INFO : saved aclImdb.model\n"
     ]
    }
   ],
   "source": [
    "model.save('aclImdb.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75839"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'women' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 75839\n"
     ]
    }
   ],
   "source": [
    "words = sorted(model.wv.vocab.keys())\n",
    "print(\"Number of words:\", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save words to file: words.txt\n",
    "fp = open(\"words.txt\", \"w\", encoding=\"utf-8\")\n",
    "for word in words:\n",
    "    fp.write(word + '\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afterschool', 'Aftershocks', 'Afterward', 'Afterwards', 'Afterwords', 'Aga', 'Agador', 'Again', 'Against', 'Agamemnon', 'Agar', 'Agars', 'Agashe', 'Agatha', 'Age', 'Aged', 'Agency', 'Agenda', 'Agent', 'Agents', 'Ages', 'Agey', 'Aggie', 'Agi', 'Aging', 'Agnes', 'Agnew', 'Agnieszka', 'Agnihotri', 'Agnus', 'Agnès', 'Ago', 'Agostino', 'Agrabah', 'Agrade', 'Agree', 'Agreed', 'Agreement', 'Agren', 'Agrippina', 'Agro', 'Aguilar', 'Aguirre', 'Agustin', 'Agutter', 'Agutters', 'Ah', 'Aha', 'Ahab', 'Ahead']\n"
     ]
    }
   ],
   "source": [
    "print (words[1500:1550]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8743907"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman', 'man')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26157176"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('paris', 'train')  # low similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unmatching_word(words):\n",
    "    for word in words:\n",
    "        if not word in model.wv.vocab:\n",
    "            print(\"Word is not in vocabulary:\", word)\n",
    "            return None\n",
    "    return model.wv.doesnt_match(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-08 12:44:46,745 : INFO : precomputing L2-norms of word weight vectors\n",
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unmatching_word(['breakfast', 'cereal', 'dinner', 'lunch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('person', 0.7372632622718811),\n",
       " ('guy', 0.6792922019958496),\n",
       " ('soldier', 0.6550565361976624),\n",
       " ('killer', 0.6520779132843018),\n",
       " ('boy', 0.6508388519287109),\n",
       " ('woman', 0.638922929763794)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The word 'woman' comes out 6th as the most similar\n",
    "model.most_similar(positive=['king', 'man'], negative=['queen'], topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('higher', 0.7832080125808716),\n",
       " ('greater', 0.6772675514221191),\n",
       " ('funnier', 0.6765692234039307),\n",
       " ('More', 0.6740158796310425),\n",
       " ('bigger', 0.6664255857467651),\n",
       " ('cheaper', 0.6573895215988159),\n",
       " ('dumber', 0.6536562442779541),\n",
       " ('scarier', 0.6463117599487305),\n",
       " ('uglier', 0.6443842053413391),\n",
       " ('quicker', 0.6440134644508362)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['low', 'lower'], negative=['high'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.361104    0.190657    0.14281137 -0.21910924 -0.15460844  0.1962104\n",
      "  0.12719002 -0.14337867 -0.46280435  0.448402   -0.03699146  0.31851628\n",
      " -0.29610476 -0.41346842  0.31622934  0.1828613   0.55195045 -0.3636207\n",
      "  0.25049934 -0.11199825 -0.0961617   0.03697551 -0.05407988 -0.7127565\n",
      "  0.37536404  0.04514764 -0.19552095 -0.09615923  0.04099998 -0.16848631\n",
      " -0.31574374  0.32440543  0.33974066  0.30078834 -0.53485286 -0.00327764\n",
      "  0.47179636  0.4307772   0.35343587  0.34145278  0.87021303 -0.40276602\n",
      "  0.07428315  0.03480908  0.06824161 -0.11767775 -0.3321068  -0.04795282\n",
      "  0.23878944 -0.14243603  0.09008274 -0.12202803 -0.40510413 -0.27023304\n",
      " -0.18543649 -0.06488868 -0.18493608  0.05292498  0.76916003 -0.04596116\n",
      "  0.13890158  0.19652385 -0.25257763  0.09267151 -0.47033966 -0.06862667\n",
      "  0.10347904 -0.07482861 -0.4453664   0.10569251 -0.32196185 -0.12069732\n",
      "  0.09291036 -0.1328929   0.5519674  -0.29313296 -0.32023013  0.6032624\n",
      " -0.18750583  0.6700869  -0.14192538 -0.3616553   0.30445704 -0.16334757\n",
      "  0.08567701  0.13738072 -0.25258812 -0.36077347  0.01502212 -0.34444818\n",
      "  0.29959652  0.28867424 -0.6976229   0.32736382 -0.73530763 -0.60811377\n",
      " -0.09836514 -0.63942474 -0.2096239  -0.15238106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prapt\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
